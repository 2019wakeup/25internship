## 核心概念

**IoU (Intersection over Union) / 交并比:**

是衡量 *预测边界框* (Predicted Bounding Box) 与 *真实边界框* (Ground Truth Bounding Box) 重叠程度的标准。

- 计算方法：`IoU = Area of Intersection / Area of Union`
- IoU 的值范围在 0 到 1 之间。值越大，表示预测框与真实框重叠越好，定位越准。
- 通常会设定一个 **IoU 阈值** (e.g., 0.5, 0.75)。只有当预测框与真实框的 IoU 大于这个阈值时，才认为这个预测框是“定位正确”的。

**TP (True Positive) / 真正例:**

- 一个**正确**的检测结果。
- 条件：检测到了一个真实存在的物体 + 预测的类别正确 + 预测框与真实框的 IoU ≥ 预设阈值。

**FP (False Positive) / 假正例:**

- 一个**错误**的检测结果。
- 可能情况：
  - 检测到的区域实际没有物体（背景误报）。
  - 检测到了物体，但预测的类别错误。
  - 检测到了物体，类别也正确，但预测框与真实框的 IoU < 预设阈值（定位不准）。
  - 对同一个真实物体进行了重复检测（多余的框算作 FP）。

**FN (False Negative) / 假负例:**

- 一个**漏掉**的检测结果。
- 情况：图像中实际存在一个物体，但模型未能检测到它。



### 基于 TP, FP, FN，可以计算出以下常用的指标：

1. **Precision / 精确率:**

   - **含义:** 在所有模型**预测为正例**（检测到的目标）的结果中，**真正是正例**（检测正确）的比例。
   - **公式:** `Precision = TP / (TP + FP)`
   - **解读:** Precision 衡量模型的**查准率**。高 Precision 意味着模型产生的错误检测（假警报）较少。

2. **Recall / 召回率 (也叫 Sensitivity / True Positive Rate):**

   - **含义:** 在所有**实际为正例**（图像中真实存在的目标）中，被模型**成功检测出来**（预测为正例）的比例。
   - **公式:** `Recall = TP / (TP + FN)`
   - **解读:** Recall 衡量模型的**查全率**。高 Recall 意味着模型漏掉的真实目标较少。

3. **Precision-Recall (PR) Curve / PR 曲线:**

   - 模型通常会为每个检测结果输出一个置信度分数 (Confidence Score)。通过调整置信度阈值，可以得到不同的 Precision 和 Recall 值对。以 Recall 为横轴，Precision 为纵轴绘制曲线，即为 PR 曲线。
   - 理想情况下，曲线越靠近右上角（Precision 和 Recall 都高）越好。

4. **AP (Average Precision) / 平均精度:**

   - **含义:** PR 曲线下的面积。这是一个综合衡量模型在**单个类别**上性能的指标，它考虑了不同置信度阈值下的 Precision 和 Recall 表现。
   - **计算:** 有多种计算方法（如 11 点插值法、所有点积分法），但核心思想是概括 PR 曲线的整体性能。AP 值越高越好。

5. **mAP (mean Average Precision) / 平均精度均值:**

   - **含义:** 对数据集中**所有物体类别**的 AP 值求平均。这是衡量模型在整个数据集上**整体性能**的最常用指标。

   - **计算:** `mAP = (Sum of AP for all classes) / (Number of classes)`

   - 注意:

      

     mAP 的计算通常与特定的 IoU 阈值相关联。例如：

     - **mAP@0.5 (或 mAP50):** 指的是在 IoU 阈值设置为 0.5 时计算得到的 mAP。这是 PASCAL VOC 等竞赛常用的标准。
     - **mAP@0.75 (或 mAP75):** 指的是在 IoU 阈值设置为 0.75 时计算得到的 mAP，要求更精确的定位。
     - **mAP@[.5:.05:.95] (COCO 标准):** 指的是在 IoU 阈值从 0.5 到 0.95、步长为 0.05 的一系列阈值下分别计算 mAP，然后对这些 mAP 值求平均。这个标准对定位精度要求更高、更全面。

6. **F1-Score:**

   - **含义:** Precision 和 Recall 的调和平均数，用于综合评价两者。当 Precision 和 Recall 都高时，F1-Score 也高。
   - **公式:** `F1 = 2 * (Precision * Recall) / (Precision + Recall)`
   - **解读:** 提供了一个平衡 Precision 和 Recall 的单一指标。