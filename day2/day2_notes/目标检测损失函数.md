**任务拆解：目标检测=分类+回归（定位）+置信度**

## 常见损失函数

1. **分类损失 (Classification Loss)**
   - **目标**：判断模型预测的边界框（Bounding Box）里包含的是哪个类别的物体（例如，是“车辆”还是“背景”，或者在多类别检测中是“轿车”、“卡车”、“行人”等）。
   - 常用函数
     - **交叉熵损失 (Cross-Entropy Loss)**：这是分类任务中最基础、最常用的损失函数。
       - **二元交叉熵 (Binary Cross-Entropy, BCE)**：适用于只有**两个类别**的情况，比如仅仅判断是“目标物体”还是“背景”。在很多检测器中，即使有多类物体，也会在每个类别上使用BCE（判断“是/不是”这个类别）。
       - **多类别交叉熵 (Categorical Cross-Entropy)**：适用于需要从多个互斥类别中选择一个的情况。
     - **焦点损失 (Focal Loss)**：这是对交叉熵损失的一种改进，主要为了解决目标检测中常见的**类别不平衡**问题（即图像中背景区域的数量远超目标物体区域）。Focal Loss通过降低容易分类样本（比如大片明确的背景）对总损失的贡献权重，使得模型能够更加专注于学习那些难以分类的样本（比如小目标、模糊目标、易与背景混淆的目标等）。这在单阶段检测器（如RetinaNet, FCOS）中尤其常用。

2. **回归损失 / 定位损失 (Regression Loss / Localization Loss)**

- **目标**：衡量模型预测的边界框位置与真实物体边界框（Ground Truth Box）之间的差距，**目的是让预测框尽可能地接近真实框**。边界框通常用中心点坐标(x, y)、宽度(w)和高度(h)来表示，或者是左上角和右下角坐标(x1, y1, x2, y2)。
- 常用函数：
  - **L1 损失 (Mean Absolute Error, MAE)**：计算**预测框坐标值与真实框坐标值之差的绝对值的平均值**。相比L2损失，它对异常值（outliers）不那么敏感，更加**鲁棒**。
  - **L2 损失 (Mean Squared Error, MSE)**：计算**预测框坐标值与真实框坐标值之差的平方的平均值**。它对误差变化很敏感，但缺点是当误差很大时，其平方项会导致损失值和梯度都非常大，可能不利于训练的稳定性，且对异常值**敏感**。
  - **Smooth L1 损失**：这是Faster R-CNN等经典检测器中广泛使用的损失函数。它结合了L1和L2损失的优点：在误差较小（接近0）时，表现类似L2损失（平方误差），使得损失函数平滑且利于收敛；在误差较大时，表现类似L1损失，可以限制梯度的数值，避免梯度爆炸，对异常值也更鲁棒。
  - **基于 IoU 的损失 (IoU-based Losses)**：这类损失函数的核心思想是直接优化目标检测任务的评价指标——交并比 (Intersection over Union, IoU)。IoU衡量的是预测框与真实框的重叠程度。直接优化IoU被认为比单独优化坐标差值更符合任务目标。常见的有：
    - **IoU Loss** (`1 - IoU`)：最简单的形式。缺点是当两个框完全不重叠时（IoU=0），损失恒为1，无法提供梯度信息。
    - **GIoU Loss (Generalized IoU)**：解决了IoU Loss在不重叠情况下的问题，引入了包含预测框和真实框的最小外接矩形作为惩罚项。
    - **DIoU Loss (Distance IoU)**：在GIoU的基础上，额外考虑了预测框中心点与真实框中心点之间的距离。
    - **CIoU Loss (Complete IoU)**：在DIoU的基础上，进一步考虑了预测框与真实框宽高比的一致性。
    - **EIoU Loss, SIoU Loss** 等：更多改进版本，试图更全面地衡量边界框回归的质量。

## 本论文用到的损失函数

1. **分类损失 (Classification Loss)**：使用的是 **交叉熵损失 (Cross Entropy Loss)**。
2. **回归损失 (Regression Loss)**：使用的是 **L1 损失 (L1 Loss)**。这用于惩罚预测的车辆边界框坐标与真实边界框坐标之间的绝对差值，目标是让预测框定位更准确。
3. **Objectness 损失 (Objectness Loss)**：明确提到了使用 **Objectness 损失**。这通常用于判断模型在某个位置预测的框内是否真的包含一个车辆目标（即区分前景/背景）。